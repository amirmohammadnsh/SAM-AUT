CUDA_VISIBLE_DEVICES=0 torchrun --standalone inference.py --split "k_fold" --model_cfg sam2_hiera_t --checkpoint ./checkpoints/sam2_hiera_tiny.pt   --task_name "Hiera_Tiny_918_1e-5_2_ND" --batch_size 32  --selected_blocks 1 --finetune_mode 0 --min_area 4.5 
# CUDA_VISIBLE_DEVICES=1 torchrun --standalone inference.py --split "k_fold" --model_cfg sam2_hiera_s --checkpoint ./checkpoints/sam2_hiera_small.pt  --task_name "Hiera_Small_918_1e-5_1_ND" --batch_size 32  --selected_blocks 1 --finetune_mode 0 --min_area 4.5 
# CUDA_VISIBLE_DEVICES=0 torchrun --standalone inference.py --split "k_fold" --model_cfg sam2_hiera_b+ --checkpoint ./checkpoints/sam2_hiera_base_plus.pt  --task_name "Hiera_Base+_918_1e-5_2_ND" --batch_size 32  --selected_blocks 1 --finetune_mode 0 --min_area 4.5 
# CUDA_VISIBLE_DEVICES=3 torchrun --standalone inference.py --split "k_fold" --model_cfg sam2_hiera_l --checkpoint ./checkpoints/sam2_hiera_large.pt  --task_name "LoRA_Hiera_Large_918_1e-3_1_ND" --batch_size 32 --selected_blocks 1 --finetune_mode 0 --min_area 4.5 --encoder_lora_layer 23 33 43

